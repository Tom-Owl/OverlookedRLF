{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lei/anaconda3/envs/RLF/lib/python3.8/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import gc\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from Roberta_SA import *\n",
    "from GPT2_SA import *\n",
    "from T5_SA import *\n",
    "from LLaMA2_SA import *\n",
    "\n",
    "def underline_words_in_red(text, words_to_underline):\n",
    "    \"\"\" Underline words that are present in words_to_underline with a red underline. \"\"\"\n",
    "    for word in words_to_underline:\n",
    "        text = text.replace(word, f'<u style=\"color: black;\">{word}</u>')\n",
    "    return text\n",
    "\n",
    "def visualize_importance(input_items, normalized_importance, words_to_underline=[]):\n",
    "    \"\"\" General function to visualize importance for any granularity - word, token, sentence. \"\"\"\n",
    "    max_alpha = 0.5\n",
    "    highlighted_text = []\n",
    "\n",
    "    for i in range(len(input_items)):\n",
    "        item = input_items[i]\n",
    "        weight = normalized_importance[i]\n",
    "        item = item.replace('Ġ', '').replace('▁', '') # 'Ġ' roberta; '▁' T5\n",
    "        if weight is not None:\n",
    "            highlighted_item = f'<span style=\"background-color:rgba(135,206,250,{weight / max_alpha});\">{item}</span>'\n",
    "        else:\n",
    "            highlighted_item = item\n",
    "        highlighted_text.append(highlighted_item)\n",
    "\n",
    "    combined_text = ' '.join(highlighted_text)\n",
    "    combined_text = underline_words_in_red(combined_text, words_to_underline)\n",
    "    display(HTML(combined_text))\n",
    "    #return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv('../data/sample_data.csv')\n",
    "index = 101\n",
    "rlf_sent = df_sample.iloc[index]['rlf_sent']\n",
    "label = int(df_sample.iloc[index]['label'])\n",
    "rlf_word = df_sample.iloc[index]['rlf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['girls', 'bonfire', 'at', \"annie's,\", 'sooo', 'fun.']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model:  siebert/sentiment-roberta-large-english\n",
      "get_sentiment: 0/0\n",
      "zero_shot RoBERTa: \n",
      "predict sentiment label:  1\n",
      "Sexp = 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.07524317346413326);\">girls</span> <span style=\"background-color:rgba(135,206,250,0.14805876504187163);\">bonfire</span> <span style=\"background-color:rgba(135,206,250,0.41747764038091445);\">at</span> <span style=\"background-color:rgba(135,206,250,0.44660387701200976);\">annie's,</span> <span style=\"background-color:rgba(135,206,250,0.0);\">sooo</span> <span style=\"background-color:rgba(135,206,250,0.912616544101071);\">fun.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can load fine-tuned roberta by setting output_dir to checkpoint folder path and load_best = True\n",
    "zeroshot_roberta = Roberta_SA(\n",
    "                output_dir = '',\n",
    "                load_best = False\n",
    "            )\n",
    "pred_y_list = zeroshot_roberta.get_sentiment([rlf_sent])\n",
    "w_list, wis_list = zeroshot_roberta.get_text_list_w_imp([rlf_sent], [label])\n",
    "print('zero_shot RoBERTa: ')\n",
    "print('predict sentiment label: ', pred_y_list[0])\n",
    "rlf_word_index = w_list[0].index(rlf_word)\n",
    "print('Sexp = {}'.format(wis_list[0][rlf_word_index]))\n",
    "visualize_importance(w_list[0], wis_list[0])\n",
    "del zeroshot_roberta\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model:  michelecafagna26/gpt2-medium-finetuned-sst2-sentiment\n",
      "zero_shot GPT2: \n",
      "predict sentiment label:  1\n",
      "Sexp = 0.04761912425369596\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.09523824850739192);\">girls</span> <span style=\"background-color:rgba(135,206,250,0.0);\">bonfire</span> <span style=\"background-color:rgba(135,206,250,0.09523824850739192);\">at</span> <span style=\"background-color:rgba(135,206,250,0.1904764572782995);\">annie's,</span> <span style=\"background-color:rgba(135,206,250,0.09523824850739192);\">sooo</span> <span style=\"background-color:rgba(135,206,250,1.5238087971995247);\">fun.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can load fine-tuned roberta by setting output_dir to checkpoint folder path and load_best = True\n",
    "zeroshot_gpt2 = GPT2_SA(\n",
    "                output_dir = '',\n",
    "                load_best = False\n",
    "            )\n",
    "pred_y_list = zeroshot_gpt2.get_sentiment([rlf_sent])\n",
    "w_list, wis_list = zeroshot_gpt2.get_text_list_w_imp([rlf_sent], [label])\n",
    "print('zero_shot GPT2: ')\n",
    "print('predict sentiment label: ', pred_y_list[0])\n",
    "rlf_word_index = w_list[0].index(rlf_word)\n",
    "print('Sexp = {}'.format(wis_list[0][rlf_word_index]))\n",
    "visualize_importance(w_list[0], wis_list[0])\n",
    "del zeroshot_gpt2\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model:  mrm8488/t5-base-finetuned-imdb-sentiment\n",
      "zero_shot T5: \n",
      "predict sentiment label:  1\n",
      "Sexp = 0.0718627542656454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lei/anaconda3/envs/RLF/lib/python3.8/site-packages/transformers/generation/utils.py:1154: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.08435200900986829);\">girls</span> <span style=\"background-color:rgba(135,206,250,0.22494050035458446);\">bonfire</span> <span style=\"background-color:rgba(135,206,250,0.0);\">at</span> <span style=\"background-color:rgba(135,206,250,0.2171084097439544);\">annie's,</span> <span style=\"background-color:rgba(135,206,250,0.1437255085312908);\">sooo</span> <span style=\"background-color:rgba(135,206,250,1.329873572360302);\">fun.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can load fine-tuned roberta by setting output_dir to checkpoint folder path and load_best = True\n",
    "zeroshot_t5 = T5_SA(\n",
    "                output_dir = '',\n",
    "                load_best = False\n",
    "            )\n",
    "pred_y_list = zeroshot_t5.get_sentiment([rlf_sent])\n",
    "w_list, wis_list = zeroshot_t5.get_text_list_w_imp([rlf_sent], [label])\n",
    "print('zero_shot T5: ')\n",
    "print('predict sentiment label: ', pred_y_list[0])\n",
    "rlf_word_index = w_list[0].index(rlf_word)\n",
    "print('Sexp = {}'.format(wis_list[0][rlf_word_index]))\n",
    "visualize_importance(w_list[0], wis_list[0])\n",
    "del zeroshot_t5\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot LLaMA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a522aea326314833bad9a93330291a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_shot LLaMA2: \n",
      "predict sentiment label:  1\n",
      "Sexp = 0.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.2);\">girls</span> <span style=\"background-color:rgba(135,206,250,0.4);\">bonfire</span> <span style=\"background-color:rgba(135,206,250,0.0);\">at</span> <span style=\"background-color:rgba(135,206,250,0.8);\">sooo</span> <span style=\"background-color:rgba(135,206,250,0.6);\">fun</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zeroshot_llama2 = LLaMA2_SA(\n",
    "                lora_model_path = '',\n",
    "                load_best = False\n",
    "            )\n",
    "pred_y_list = zeroshot_llama2.get_sentiment([rlf_sent])\n",
    "w_list, wis_list = zeroshot_llama2.get_text_list_w_imp([rlf_sent])\n",
    "print('zero_shot LLaMA2: ')\n",
    "print('predict sentiment label: ', pred_y_list[0])\n",
    "rlf_word_index = w_list[0].index(rlf_word)\n",
    "print('Sexp = {}'.format(wis_list[0][rlf_word_index]))\n",
    "visualize_importance(w_list[0], wis_list[0])\n",
    "del zeroshot_llama2\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExpInstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19efb8e21b34999b82ec7eec58b68ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExpInstruct LLaMA2: \n",
      "predict sentiment label:  1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'sooo' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9208/3753742702.py\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ExpInstruct LLaMA2: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict sentiment label: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrlf_word_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlf_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sexp = {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwis_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrlf_word_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mvisualize_importance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwis_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'sooo' is not in list"
     ]
    }
   ],
   "source": [
    "ExpInstruct_llama2 = LLaMA2_SA(\n",
    "                lora_model_path = '../ft_model/llama2/folder_0/checkpoint-6000',\n",
    "                load_best = True\n",
    "            )\n",
    "pred_y_list = ExpInstruct_llama2.get_sentiment([rlf_sent])\n",
    "w_list, wis_list = ExpInstruct_llama2.get_text_list_w_imp([rlf_sent])\n",
    "print('ExpInstruct LLaMA2: ')\n",
    "print('predict sentiment label: ', pred_y_list[0])\n",
    "rlf_word_index = w_list[0].index(rlf_word)\n",
    "print('Sexp = {}'.format(wis_list[0][rlf_word_index]))\n",
    "visualize_importance(w_list[0], wis_list[0])\n",
    "del ExpInstruct_llama2\n",
    "gc.collect();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
