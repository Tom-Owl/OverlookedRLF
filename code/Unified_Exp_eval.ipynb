{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gc\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from Roberta_SA import *\n",
    "from GPT2_SA import *\n",
    "from T5_SA import *\n",
    "from LLaMA2_SA import *\n",
    "\n",
    "def underline_words_in_red(text, words_to_underline):\n",
    "    \"\"\" Underline words that are present in words_to_underline with a red underline. \"\"\"\n",
    "    for word in words_to_underline:\n",
    "        text = text.replace(word, f'<u style=\"color: black;\">{word}</u>')\n",
    "    return text\n",
    "\n",
    "def visualize_importance(input_items, normalized_importance, words_to_underline=[]):\n",
    "    \"\"\" General function to visualize importance for any granularity - word, token, sentence. \"\"\"\n",
    "    max_alpha = 0.5\n",
    "    highlighted_text = []\n",
    "\n",
    "    for i in range(len(input_items)):\n",
    "        item = input_items[i]\n",
    "        weight = normalized_importance[i]\n",
    "        item = item.replace('Ġ', '').replace('▁', '') # 'Ġ' roberta; '▁' T5\n",
    "        if weight is not None:\n",
    "            highlighted_item = f'<span style=\"background-color:rgba(135,206,250,{weight / max_alpha});\">{item}</span>'\n",
    "        else:\n",
    "            highlighted_item = item\n",
    "        highlighted_text.append(highlighted_item)\n",
    "\n",
    "    combined_text = ' '.join(highlighted_text)\n",
    "    combined_text = underline_words_in_red(combined_text, words_to_underline)\n",
    "    display(HTML(combined_text))\n",
    "    #return combined_text\n",
    "    \n",
    "def get_rlf_index(w_list, rlf_word):\n",
    "    rlf_word_index = -1\n",
    "    for i in range(len(w_list)):\n",
    "        if rlf_word in w_list[i]:\n",
    "            rlf_word_index = i\n",
    "    return rlf_word_index\n",
    "\n",
    "def get_Sexp(w_list, rlf_word, wis_list):\n",
    "    rlf_word_index = get_rlf_index(w_list, rlf_word)\n",
    "    if rlf_word_index == -1:\n",
    "        return 1/len(w_list[0])\n",
    "    else:\n",
    "        return wis_list[rlf_word_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv('../data/sample_data.csv')\n",
    "index = 101\n",
    "rlf_sent = df_sample.iloc[index]['rlf_sent']\n",
    "label = int(df_sample.iloc[index]['label'])\n",
    "rlf_word = df_sample.iloc[index]['rlf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model:  siebert/sentiment-roberta-large-english\n",
      "get_sentiment: 0/0\n",
      "zero_shot RoBERTa: \n",
      "predict sentiment label:  1\n",
      "Sexp = 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.07524317346413326);\">girls</span> <span style=\"background-color:rgba(135,206,250,0.14805876504187163);\">bonfire</span> <span style=\"background-color:rgba(135,206,250,0.41747764038091445);\">at</span> <span style=\"background-color:rgba(135,206,250,0.44660387701200976);\">annie's,</span> <span style=\"background-color:rgba(135,206,250,0.0);\">sooo</span> <span style=\"background-color:rgba(135,206,250,0.912616544101071);\">fun.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can load fine-tuned roberta by setting output_dir to checkpoint folder path and load_best = True\n",
    "zeroshot_roberta = Roberta_SA(\n",
    "                output_dir = '',\n",
    "                load_best = False\n",
    "            )\n",
    "pred_y_list = zeroshot_roberta.get_sentiment([rlf_sent])\n",
    "w_list, wis_list = zeroshot_roberta.get_text_list_w_imp([rlf_sent], [label])\n",
    "print('zero_shot RoBERTa: ')\n",
    "print('predict sentiment label: ', pred_y_list[0])\n",
    "Sexp = get_Sexp(w_list[0], rlf_word, wis_list[0])\n",
    "print('Sexp = {}'.format(Sexp))\n",
    "visualize_importance(w_list[0], wis_list[0])\n",
    "del zeroshot_roberta\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model:  michelecafagna26/gpt2-medium-finetuned-sst2-sentiment\n",
      "zero_shot GPT2: \n",
      "predict sentiment label:  1\n",
      "Sexp = 0.04761912425369596\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.09523824850739192);\">girls</span> <span style=\"background-color:rgba(135,206,250,0.0);\">bonfire</span> <span style=\"background-color:rgba(135,206,250,0.09523824850739192);\">at</span> <span style=\"background-color:rgba(135,206,250,0.1904764572782995);\">annie's,</span> <span style=\"background-color:rgba(135,206,250,0.09523824850739192);\">sooo</span> <span style=\"background-color:rgba(135,206,250,1.5238087971995247);\">fun.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can load fine-tuned roberta by setting output_dir to checkpoint folder path and load_best = True\n",
    "zeroshot_gpt2 = GPT2_SA(\n",
    "                output_dir = '',\n",
    "                load_best = False\n",
    "            )\n",
    "pred_y_list = zeroshot_gpt2.get_sentiment([rlf_sent])\n",
    "w_list, wis_list = zeroshot_gpt2.get_text_list_w_imp([rlf_sent], [label])\n",
    "print('zero_shot GPT2: ')\n",
    "print('predict sentiment label: ', pred_y_list[0])\n",
    "Sexp = get_Sexp(w_list[0], rlf_word, wis_list[0])\n",
    "print('Sexp = {}'.format(Sexp))\n",
    "visualize_importance(w_list[0], wis_list[0])\n",
    "del zeroshot_gpt2\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model:  mrm8488/t5-base-finetuned-imdb-sentiment\n",
      "zero_shot T5: \n",
      "predict sentiment label:  1\n",
      "Sexp = 0.0718627542656454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lei/anaconda3/envs/RLF/lib/python3.8/site-packages/transformers/generation/utils.py:1154: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.08435200900986829);\">girls</span> <span style=\"background-color:rgba(135,206,250,0.22494050035458446);\">bonfire</span> <span style=\"background-color:rgba(135,206,250,0.0);\">at</span> <span style=\"background-color:rgba(135,206,250,0.2171084097439544);\">annie's,</span> <span style=\"background-color:rgba(135,206,250,0.1437255085312908);\">sooo</span> <span style=\"background-color:rgba(135,206,250,1.329873572360302);\">fun.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can load fine-tuned roberta by setting output_dir to checkpoint folder path and load_best = True\n",
    "zeroshot_t5 = T5_SA(\n",
    "                output_dir = '',\n",
    "                load_best = False\n",
    "            )\n",
    "pred_y_list = zeroshot_t5.get_sentiment([rlf_sent])\n",
    "w_list, wis_list = zeroshot_t5.get_text_list_w_imp([rlf_sent], [label])\n",
    "print('zero_shot T5: ')\n",
    "print('predict sentiment label: ', pred_y_list[0])\n",
    "Sexp = get_Sexp(w_list[0], rlf_word, wis_list[0])\n",
    "print('Sexp = {}'.format(Sexp))\n",
    "visualize_importance(w_list[0], wis_list[0])\n",
    "del zeroshot_t5\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot LLaMA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43293d8cf12f4a9bb26f703eff73b596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero_shot LLaMA2: \n",
      "predict sentiment label:  1\n",
      "Sexp = 0.38709677419354843\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.19354838709677422);\">girls</span> <span style=\"background-color:rgba(135,206,250,0.38709677419354843);\">bonfire</span> <span style=\"background-color:rgba(135,206,250,0.0);\">at</span> <span style=\"background-color:rgba(135,206,250,0.3225806451612903);\">annie's,</span> <span style=\"background-color:rgba(135,206,250,0.7741935483870969);\">sooo</span> <span style=\"background-color:rgba(135,206,250,0.3225806451612903);\">fun.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zeroshot_llama2 = LLaMA2_SA(\n",
    "                lora_model_path = '',\n",
    "                load_best = False\n",
    "            )\n",
    "pred_y_list = zeroshot_llama2.get_sentiment([rlf_sent])\n",
    "w_list, wis_list = zeroshot_llama2.get_text_list_w_imp([rlf_sent])\n",
    "print('zero_shot LLaMA2: ')\n",
    "print('predict sentiment label: ', pred_y_list[0])\n",
    "Sexp = get_Sexp(w_list[0], rlf_word, wis_list[0])\n",
    "print('Sexp = {}'.format(Sexp))\n",
    "visualize_importance(w_list[0], wis_list[0])\n",
    "del zeroshot_llama2\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExpInstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff57f39767cc492799ed7387b630ec47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExpInstruct LLaMA2: \n",
      "predict sentiment label:  1\n",
      "Sexp = 0.34285714285714286\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.17142857142857143);\">girls</span> <span style=\"background-color:rgba(135,206,250,0.34285714285714286);\">bonfire</span> <span style=\"background-color:rgba(135,206,250,0.0);\">at</span> <span style=\"background-color:rgba(135,206,250,0.2857142857142857);\">annie's,</span> <span style=\"background-color:rgba(135,206,250,0.6857142857142857);\">sooo</span> <span style=\"background-color:rgba(135,206,250,0.5142857142857142);\">fun.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ExpInstruct_llama2 = LLaMA2_SA(\n",
    "                lora_model_path = '../ft_model/llama2/folder_0/checkpoint-6000',\n",
    "                load_best = True\n",
    "            )\n",
    "pred_y_list = ExpInstruct_llama2.get_sentiment([rlf_sent])\n",
    "w_list, wis_list = ExpInstruct_llama2.get_text_list_w_imp([rlf_sent])\n",
    "print('ExpInstruct LLaMA2: ')\n",
    "print('predict sentiment label: ', pred_y_list[0])\n",
    "Sexp = get_Sexp(w_list[0], rlf_word, wis_list[0])\n",
    "print('Sexp = {}'.format(Sexp))\n",
    "visualize_importance(w_list[0], wis_list[0])\n",
    "del ExpInstruct_llama2\n",
    "gc.collect();  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RLF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
